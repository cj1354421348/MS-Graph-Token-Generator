import json
import os
import psycopg2
import sys
import logging
from datetime import datetime
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Configuration
ACCOUNTS_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "accounts.json")
REPORT_FILE = os.path.join("logs", "sync_report.json")
DB_URL = os.environ.get("DB_URL")

if not DB_URL:
    logger.error("âŒ Error: DB_URL not found in environment variables.")
    # æˆ‘ä»¬ä¸ç›´æ¥é€€å‡ºäº†ï¼Œè€Œæ˜¯ç”Ÿæˆä¸€ä¸ªé”™è¯¯æŠ¥å‘Šï¼Œè®© scheduler çŸ¥é“
    # sys.exit(1) 

def ensure_logs_dir():
    if not os.path.exists("logs"):
        os.makedirs("logs")

def load_local_accounts():
    """è¯»å–æœ¬åœ° accounts.json"""
    if not os.path.exists(ACCOUNTS_FILE):
        logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {ACCOUNTS_FILE}")
        return {}
    try:
        with open(ACCOUNTS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"âŒ è¯»å–æœ¬åœ°æ–‡ä»¶å¤±è´¥: {e}")
        return {}

def save_report(stats, error=None):
    report = {
        "timestamp": datetime.now().isoformat(),
        "stats": stats,
        "error": str(error) if error else None
    }
    try:
        with open(REPORT_FILE, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        logger.info(f"ğŸ“ åŒæ­¥æŠ¥å‘Šå·²å†™å…¥: {REPORT_FILE}")
    except Exception as e:
        logger.error(f"âŒ å†™å…¥æŠ¥å‘Šå¤±è´¥: {e}")

def sync_to_db():
    ensure_logs_dir()
    
    stats = {
        "inserted": 0,
        "updated": 0,
        "skipped": 0
    }

    if not DB_URL:
        save_report(stats, "DB_URL not configured")
        return

    local_data = load_local_accounts()
    if not local_data:
        logger.warning("âš  æ²¡æœ‰æœ¬åœ°æ•°æ®ï¼Œç»“æŸåŒæ­¥ã€‚")
        save_report(stats, "No local data found")
        return

    logger.info(f"ğŸ”„ å¼€å§‹åŒæ­¥ {len(local_data)} ä¸ªæœ¬åœ°è´¦æˆ·åˆ°æ•°æ®åº“...")

    conn = None
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        for email, info in local_data.items():
            local_refresh_token = info.get("refresh_token")
            local_client_id = info.get("client_id")
            
            if not local_refresh_token or not local_client_id:
                logger.warning(f"âš ï¸ è·³è¿‡ä¸å®Œæ•´æ•°æ®: {email}")
                continue

            # 1. æŸ¥è¯¢æ•°æ®åº“æ˜¯å¦å­˜åœ¨ (å¿½ç•¥å¤§å°å†™)
            cur.execute("SELECT data, email FROM account_backups WHERE LOWER(email) = LOWER(%s)", (email,))
            row = cur.fetchone()

            if row:
                # --- æƒ…å†µ B: æ•°æ®åº“å·²å­˜åœ¨ (å¢é‡èåˆ) ---
                db_data_str = row[0]
                db_actual_email = row[1]

                try:
                    db_json = json.loads(db_data_str)
                except:
                    db_json = {} 

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                needs_update = False
                
                if db_json.get("refresh_token") != local_refresh_token:
                    db_json["refresh_token"] = local_refresh_token
                    needs_update = True
                
                if db_json.get("client_id") != local_client_id:
                    db_json["client_id"] = local_client_id
                    needs_update = True
                
                if needs_update:
                    new_data_str = json.dumps(db_json, ensure_ascii=False)
                    cur.execute("""
                        UPDATE account_backups 
                        SET data = %s, last_modified_at = NOW() 
                        WHERE email = %s
                    """, (new_data_str, db_actual_email))
                    logger.info(f"âœ… [æ›´æ–°] {db_actual_email}")
                    stats["updated"] += 1
                else:
                    stats["skipped"] += 1

            else:
                # --- æƒ…å†µ A: æ•°æ®åº“ä¸å­˜åœ¨ (æ–°å¢) ---
                new_json = {
                    "refresh_token": local_refresh_token,
                    "client_id": local_client_id
                }
                new_data_str = json.dumps(new_json, ensure_ascii=False)
                
                cur.execute("""
                    INSERT INTO account_backups (email, data, last_modified_at)
                    VALUES (%s, %s, NOW())
                """, (email, new_data_str))
                logger.info(f"ğŸ†• [æ–°å¢] {email}")
                stats["inserted"] += 1

        conn.commit()
        cur.close()
        
        logger.info("-" * 50)
        logger.info(f"ğŸ‰ åŒæ­¥å®Œæˆ! æ–°å¢: {stats['inserted']}, æ›´æ–°: {stats['updated']}, è·³è¿‡: {stats['skipped']}")
        logger.info("-" * 50)
        
        save_report(stats)

    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
        save_report(stats, str(e))
    finally:
        if conn:
            conn.close()

if __name__ == "__main__":
    sync_to_db()
